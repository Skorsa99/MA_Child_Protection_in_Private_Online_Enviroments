<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Test_Model</title>
    <style>
        /* Switch styling */
        .switch {
            position: relative;
            display: inline-block;
            width: 200px;
            height: 100%;
        }

        .switch input {
            opacity: 0;
            width: 0;
            height: 0;
        }

        .slider {
            position: absolute;
            cursor: pointer;
            top: 0;
            left: 0;
            right: 0;
            bottom: 0;
            background-color: red;
            transition: .4s;
            border: solid black 5px;
            box-sizing: border-box;
        }

        .slider:before {
            position: absolute;
            content: "";
            height: calc(100% - 8px);
            aspect-ratio: 1 / 1;
            left: 4px;
            bottom: 4px;
            background-color: white;
            transition: .4s;
        }

        input:checked + .slider {
            background-color: limegreen;
        }

        input:focus + .slider {
            box-shadow: 0 0 1px limegreen;
        }

        input:checked + .slider:before {
            transform: translateX(100px);
            border-bottom-left-radius: 1px;
        }

        .slider.round {
            border-radius: 10px;
            border-bottom-left-radius: 30px;
        }

        .slider.round:before {
            border-radius: 1px;
            border-bottom-left-radius: 21px;
        }

        /* File input wrapper */
        .file-input-wrapper {
            position: relative;
            width: calc(100% - 210px);
            margin-left: 10px;
            height: 100%;
        }

        /* Hide native input */
        .file-input-wrapper input[type="file"] {
            opacity: 0;
            width: 100%;
            height: 100%;
            cursor: pointer;
            position: absolute;
            top: 0;
            left: 0;
            z-index: 2;
        }

        /* Styled fake button */
        .file-input-label {
            display: flex;
            align-items: center;
            justify-content: center;
            height: 100%;
            background-color: darkgrey;
            border: solid black 5px;
            border-radius: 10px;
            font-family: sans-serif;
            font-weight: bold;
            cursor: pointer;
            transition: background-color 0.3s;
            box-sizing: border-box;
            position: relative;
            z-index: 1;
        }

        .file-input-label:hover {
            background-color: grey;
        }

        /* Video-Styling passend zum bisherigen Bild-Container */
        .video-holder{
            width:75%;
            height:100%;
            border-top-left-radius:30px;
            border-top-right-radius:10px;
            border-bottom-left-radius:10px;
            border-bottom-right-radius:10px;
            border:5px solid #000;
            box-sizing:border-box;
            object-fit:contain;       /* bei Bedarf auf 'cover' ändern */
            background: white;          /* falls kein Stream, schwarzer Hintergrund */
        }
        
        .video-holder-safe {
        border:5px solid limegreen;
        }
        
        .video-holder-unsafe {
            border:5px solid red;
        }
    
        .video-holder-empty {
            border:5px solid black;
        }
        
        .processed_video_holder {
            width: 100%;
            aspect-ratio: 1 / 1;
            max-height: calc(100% - 55px);
            border-top-left-radius: 10px;
            border-top-right-radius: 30px;
            border-bottom-left-radius: 10px;
            border-bottom-right-radius: 10px;
            border: 5px solid #000;
            box-sizing: border-box;
            background: white;          /* falls kein Stream, schwarzer Hintergrund */
            background-size: contain;
            background-position: center center;
            background-repeat: no-repeat;
        }
    </style>
</head>
<body style="padding: 30px; height: 100vh; width: 100vw; box-sizing: border-box; border: none;">
    <div style="height: calc(100% - 110px); display: flex; flex-direction: row;">
        <video id="video-holder" class="video-holder" autoplay muted playsinline></video>
        <div style="width: calc(35% - 10px); height: 100%; margin-left: 10px; display: flex; flex-direction: column;">
            <div id="processed_video_holder" class="processed_video_holder"></div>
            <div class=""></div>
        </div>
    </div>
    <div style="height: calc(100px); margin-top: 10px; display: flex; flex-direction: row;">
        <label class="switch">
            <input id="cam-toggle" type="checkbox">
            <span class="slider round"></span>
        </label>
        <div class="file-input-wrapper">
            <label class="file-input-label">Upload File</label>
            <input type="file" id="file-input">
        </div>
    </div>
    <script src="https://unpkg.com/@tensorflow/tfjs@latest/dist/tf.min.js"></script>
    <script>
        const videoEl   = document.getElementById('video-holder');
        const camToggle = document.getElementById('cam-toggle');

        let currentStream = null;

        async function startCamera(){
            // Stoppe evtl. alte Streams sauber
            stopCamera();

            try {
                const constraints = {
                    video: {
                        facingMode: "user",         // Frontkamera auf Mobilgeräten
                        width: { ideal: 1280 },
                        height:{ ideal: 720 }
                    },
                audio: false                  // auf true setzen, wenn Ton gewünscht ist
                };

                const stream = await navigator.mediaDevices.getUserMedia(constraints);
                currentStream = stream;
                videoEl.srcObject = stream;
                // Autoplay-Hinweis: muted + playsinline sind gesetzt

                const stopLoop = startFrameLoop(
                    document.getElementById('video-holder'),
                    (imgData, canvas) => {
                        // console.log(imgData); // or send it somewhere
                    }
                );
            } catch (err) {
                camToggle.checked = false;
                console.error(err);
                alert(
                    (location.protocol !== 'https:' && location.hostname !== 'localhost')
                    ? 'getUserMedia erfordert HTTPS oder localhost.'
                    : 'Kamera konnte nicht gestartet werden. Prüfe Berechtigungen und Geräte.'
                );
            }
        }

        function stopCamera(){
            if (currentStream){
                currentStream.getTracks().forEach(t => t.stop());
                currentStream = null;
                videoEl.srcObject = null;
                
                const stopLoop = startFrameLoop(
                    document.getElementById('video-holder'),
                    (imgData, canvas) => {
                        // console.log(imgData); // or send it somewhere
                    }
                );
            }
        }

        // Toggle steuert Kamera
        camToggle.addEventListener('change', () => {
            if (camToggle.checked) startCamera(); else stopCamera();
        });

        // Optional: beim Laden NICHT automatisch starten – User soll togglen.
        // Wenn du automatisch starten willst, einfach:
        // window.addEventListener('load', () => { camToggle.checked = true; startCamera(); });

        // (Optional) Nette Kleinigkeit: auf Größenänderungen reagieren
        window.addEventListener('beforeunload', stopCamera);

        function startFrameLoop(videoEl, callback) {
            const canvas = document.createElement('canvas');
            const ctx = canvas.getContext('2d');
            canvas.width = 64;
            canvas.height = 64;

            // Replace any existing content
            processedDiv = document.getElementById('processed_video_holder');
            processedDiv.innerHTML = '';
            processedDiv.appendChild(canvas);

            let running = true;

            function loop() {
                if (!running) return;

                // Draw the video frame scaled to 224x224
                ctx.drawImage(videoEl, 0, 0, 224, 224);

                // Get the scaled image data
                const imgData = ctx.getImageData(0, 0, 224, 224);

                // Send the data to the callback
                callback(imgData, canvas);

                requestAnimationFrame(loop);
            }

            loop();

            // Return a function to stop the loop
            return () => { running = false; };
        }







        // ------------------------------------------------------------------------------------------
        // - Classification logic -------------------------------------------------------------------
        // ------------------------------------------------------------------------------------------
        const MODEL_PATH = '/models/V_0_6/model.json';
        const META_PATH  = 'models/V_0_6/labels.json';
        let model = undefined;
        let META  = { classes: ['unsafe','safe','empty'], img_size: 224 };
        let IMG_SIZE = 64;
        let CLASSES  = META.classes;

        async function loadModelAndMeta() {
            try {
                const res = await fetch(META_PATH);
                if (res.ok) {
                    META = await res.json();
                    if (Array.isArray(META.classes)) CLASSES = META.classes;
                    if (typeof META.img_size === 'number') IMG_SIZE = META.img_size;
                }
            } catch (e) { console.warn('Failed to load labels.json, using defaults.', e); }
            model = await tf.loadLayersModel(MODEL_PATH);
            console.log('TFJS model loaded:', MODEL_PATH, 'img_size=', IMG_SIZE, 'classes=', CLASSES);
        }

        function updateBorder(topLabel) {
            videoEl.classList.remove('video-holder-safe', 'video-holder-unsafe', 'video-holder-empty');
            if (String(topLabel).toLowerCase() === 'empty') {
                videoEl.classList.add('video-holder-empty');
                console.log("Empty");
            } else if (String(topLabel).toLowerCase() === 'unsafe') {
                videoEl.classList.add('video-holder-unsafe');
                console.log("Unsafe");
            } else {
                videoEl.classList.add('video-holder-safe');
                console.log("Safe");
            }
        }

        function drawOverlay(ctx, probs) {
            if (!probs || !probs.length) return;
            const w = ctx.canvas.width, h = ctx.canvas.height;
            ctx.save();
            ctx.fillStyle = 'rgba(0,0,0,0.5)';
            ctx.fillRect(0, 0, w, Math.max(30, 16 * CLASSES.length + 10));
            ctx.fillStyle = 'white';
            ctx.font = '12px sans-serif';
            let y = 16;
            let maxIdx = 0, maxVal = -1;
            for (let i = 0; i < probs.length; i++) { if (probs[i] > maxVal) { maxVal = probs[i]; maxIdx = i; } }
            for (let i = 0; i < probs.length; i++) {
                const p = probs[i];
                const label = (CLASSES[i] !== undefined) ? CLASSES[i] : ('class ' + i);
                const star = (i === maxIdx) ? '★ ' : '';
                ctx.fillText(`${star}${label}: ${(p*100).toFixed(1)}%`, 8, y);
                y += 16;
            }
            ctx.restore();
        }

        async function classifyFrameFromCanvas(canvas) {
            if (!model) return null;
            // IMPORTANT: Do not return a Promise from inside tf.tidy().
            // Create the tensor inside tidy, return a TENSOR, then await .data() outside.
            const probsTensor = tf.tidy(() => {
                const input = tf.browser.fromPixels(canvas)
                    .resizeNearestNeighbor([IMG_SIZE, IMG_SIZE])
                    .toFloat()
                    .div(255)
                    .expandDims(0);
                const logits = model.predict(input);
                const t = Array.isArray(logits) ? logits[0] : logits; // ensure Tensor
                // Apply softmax unconditionally; if the model already has softmax, this is idempotent for most cases.
                return tf.softmax(t);
            });
            const probsArr = await probsTensor.data();
            probsTensor.dispose();
            return Array.from(probsArr);
        }

        // Replace startFrameLoop to use dynamic IMG_SIZE and run inference
        function startFrameLoop(videoEl, callback) {
            const canvas = document.createElement('canvas');
            const ctx = canvas.getContext('2d');
            canvas.width = IMG_SIZE;
            canvas.height = IMG_SIZE;

            processedDiv = document.getElementById('processed_video_holder');
            processedDiv.innerHTML = '';
            processedDiv.appendChild(canvas);

            let running = true;

            async function loop() {
                if (!running) return;
                ctx.drawImage(videoEl, 0, 0, IMG_SIZE, IMG_SIZE);
                let probs = null;
                try {
                    probs = await classifyFrameFromCanvas(canvas);
                } catch (e) {
                    // swallow inference errors for robustness
                }
                if (probs) {
                    // Determine top class
                    let maxIdx = 0, maxVal = -1;
                    for (let i = 0; i < probs.length; i++) { if (probs[i] > maxVal) { maxVal = probs[i]; maxIdx = i; } }
                    const topLabel = (CLASSES[maxIdx] !== undefined) ? CLASSES[maxIdx] : ('class ' + maxIdx);
                    updateBorder(topLabel);
                    drawOverlay(ctx, probs);
                }

                // If a callback was provided, pass raw ImageData too
                if (typeof callback === 'function') {
                    const imgData = ctx.getImageData(0, 0, IMG_SIZE, IMG_SIZE);
                    try { callback(imgData, canvas); } catch (e) {}
                }

                requestAnimationFrame(loop);
            }

            loop();
            return () => { running = false; };
        }

        // Kick off loading
        loadModelAndMeta();
    </script>
</body>
</html>

<!--python3 -m http.server 8000-->